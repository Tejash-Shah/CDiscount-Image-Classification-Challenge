{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io, bson, multiprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000004079</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000004141</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000015539</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1000005744</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1000004079</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1000010667</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1000018290</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1000010653</td>\n",
       "      <td>[{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id  category_id                                               imgs\n",
       "0     0   1000010653  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "1     1   1000010653  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "2     2   1000004079  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "3     3   1000004141  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "4     4   1000015539  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "5     5   1000010653  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "6     6   1000005744  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "7     7   1000004079  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "8     8   1000010667  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "9     9   1000018290  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0...\n",
       "10   11   1000010653  [{'picture': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x0..."
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"train_example.bson\",'rb')as train:\n",
    "    df=pd.DataFrame(bson.decode_all(train.read()),index=None)\n",
    "    #df.set_index('_id', inplace=True)\n",
    "df[0:11]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get binary image data\n",
    "df['imgs'] = df['imgs'].apply(lambda rec: rec[0]['picture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to raw image\n",
    "df['imgs'] = df['imgs'].apply(lambda img: Image.open(io.BytesIO(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'category_id'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df = df.sort_values(df.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000010653 1000004079 1000004141 1000015539 1000005744 1000010667\n",
      " 1000018290 1000018306 1000010961 1000015309 1000007361 1000018294\n",
      " 1000014287 1000005910 1000001859 1000010647 1000011423 1000012989\n",
      " 1000012558 1000010061 1000005990 1000012993 1000014396 1000003787\n",
      " 1000010706 1000007138 1000003191 1000010645 1000003977 1000005796\n",
      " 1000013922 1000010683 1000010641 1000010461 1000014053 1000004085]\n"
     ]
    }
   ],
   "source": [
    "cat_unique = df.category_id.unique()\n",
    "print (cat_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data =  df.shape[0]\n",
    "img_pixel_val = []\n",
    "img_category = [] \n",
    "for i in range(len_data):\n",
    "    img_pixel_val.append(np.asarray(df.imgs[i]))\n",
    "    img_category.append(df.category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 97200)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pixel_val = np.array(img_pixel_val, dtype=float)\n",
    "img_pixel_val_flat = img_pixel_val.flatten().reshape(len_data, 97200)\n",
    "img_pixel_val_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 97200)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pixel_val_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 3 columns):\n",
      "_id            82 non-null int64\n",
      "category_id    82 non-null int64\n",
      "imgs           82 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = df['category_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 1)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.reshape(train_labels, (-1,1))\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.reshape(-1,1)\n",
    "#print(cat_unique.shape)\n",
    "train_labels = enc.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 36)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "train_labels_class = train_labels.shape[1]\n",
    "print(train_labels_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 97236)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb =  np.concatenate((img_pixel_val_flat, train_labels), axis = 1)\n",
    "comb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting only row with label 18 / 19/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 36), dtype=float64)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = img_pixel_val_flat.shape[0]\n",
    "total_feature = img_pixel_val_flat.shape[1]\n",
    "total_labels = train_labels.shape[1]\n",
    "data_select = np.empty((0,total_feature))\n",
    "data_labels = np.empty((0,total_labels))\n",
    "#data_select = np.empty((0))\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35], dtype=int64),\n",
       " array([ 1,  1,  1,  1,  4,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 36,  4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  2,\n",
       "         2,  1], dtype=int64))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk = []\n",
    "for i in range(total_data):\n",
    "    chk.append(np.argmax(train_labels[i]))\n",
    "    \n",
    "np.unique(chk, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35], dtype=int64),\n",
       " array([ 1,  1,  1,  1,  4,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1, 36,  4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  2,\n",
       "         2,  1], dtype=int64))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk = []\n",
    "for i in range(total_data):\n",
    "    chk.append(np.argmax(train_labels[i]))\n",
    "np.unique(chk, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 97200)\n",
      "(36, 97200)\n",
      "(36, 36)\n"
     ]
    }
   ],
   "source": [
    "#train_values = np.empty((0))\n",
    "cnt = 0\n",
    "for i in range(total_data):\n",
    "    if (np.argmax(train_labels[i]) == 18):\n",
    "        if cnt == 0:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_select = data\n",
    "            data_labels = label\n",
    "            cnt += 1\n",
    "            print(data_select.shape)\n",
    "        else:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_select = np.append(data_select, data, axis=0)\n",
    "            data_labels = np.append(data_labels, label, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "\n",
    "print(data_select.shape) \n",
    "print(data_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 97200)\n",
      "(4, 36)\n"
     ]
    }
   ],
   "source": [
    "data_4select = np.empty((0,total_feature))\n",
    "data_4labels = np.empty((0,total_labels))\n",
    "cnt = 0\n",
    "for i in range(total_data):\n",
    "    if (np.argmax(train_labels[i]) == 4):\n",
    "        if cnt == 0:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_4select = data\n",
    "            data_4labels = label\n",
    "            cnt += 1\n",
    "            #print(data_select.shape)\n",
    "        else:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_4select = np.append(data_4select, data, axis=0)\n",
    "            data_4labels = np.append(data_4labels, label, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "print(data_4select.shape) \n",
    "print(data_4labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 97200)\n",
      "(8, 36)\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(total_data):\n",
    "    if (np.argmax(train_labels[i]) == 4):\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_4select = np.append(data_4select, data, axis=0)\n",
    "            data_4labels = np.append(data_4labels, label, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "print(data_4select.shape) \n",
    "print(data_4labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 97200)\n",
      "(4, 36)\n",
      "(8, 97200)\n",
      "(8, 36)\n"
     ]
    }
   ],
   "source": [
    "data_19select = np.empty((0,total_feature))\n",
    "data_19labels = np.empty((0,total_labels))\n",
    "cnt = 0\n",
    "for i in range(total_data):\n",
    "    if (np.argmax(train_labels[i]) == 19):\n",
    "        if cnt == 0:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_19select = data\n",
    "            data_19labels = label\n",
    "            cnt += 1\n",
    "            #print(data_select.shape)\n",
    "        else:\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_19select = np.append(data_19select, data, axis=0)\n",
    "            data_19labels = np.append(data_19labels, label, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "            \n",
    "print(data_19select.shape) \n",
    "print(data_19labels.shape)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(total_data):\n",
    "    if (np.argmax(train_labels[i]) == 19):\n",
    "            data = np.reshape(img_pixel_val_flat[i], (1, total_feature))\n",
    "            label = np.reshape(train_labels[i], (1, total_labels))\n",
    "            data_19select = np.append(data_19select, data, axis=0)\n",
    "            data_19labels = np.append(data_19labels, label, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "print(data_19select.shape) \n",
    "print(data_19labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 97200)\n",
      "(52, 1)\n"
     ]
    }
   ],
   "source": [
    "comb_data = np.concatenate((data_select, data_4select, data_19select), axis=0)\n",
    "comb_labels = np.concatenate((data_labels, data_4labels, data_19labels), axis=0)\n",
    "max_ind = np.empty((0,1))\n",
    "cnt = 0\n",
    "for i in range(comb_labels.shape[0]):\n",
    "     if cnt == 0:\n",
    "            data = np.argmax(comb_labels[i])\n",
    "            data = np.reshape(data, (1, -1))\n",
    "            max_ind = data\n",
    "            #print (max_ind.shape)\n",
    "            cnt += 1\n",
    "     else:\n",
    "            data = np.argmax(comb_labels[i])\n",
    "            data = np.reshape(data, (1, -1))\n",
    "            #print (data)\n",
    "            #print ('max',max_ind)\n",
    "            max_ind = np.append(max_ind, data, axis=0)\n",
    "            cnt +=1\n",
    "            \n",
    "\n",
    "print(comb_data.shape)\n",
    "print(max_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saish\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 36), (18, 36), (19, 36)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18,  4,  4,  4,  4,  4,  4,  4,  4, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4], dtype=int64)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "final_inp, int_label = SMOTE().fit_sample(np.asarray(comb_data), np.asarray(max_ind))\n",
    "from collections import Counter \n",
    "print(sorted(Counter(int_label).items()))\n",
    "int_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 3)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "int_label = int_label.reshape(-1,1)\n",
    "final_label = enc.fit_transform(int_label)\n",
    "final_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_inp, final_label = shuffle(final_inp, final_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "86\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "total_rows = final_inp.shape[0]\n",
    "train_split = int(total_rows * 0.8)\n",
    "rem_rows = total_rows - train_split\n",
    "print(rem_rows)\n",
    "val_split = int(rem_rows * 0.5)\n",
    "test_split = total_rows - (train_split + val_split)\n",
    "print(train_split)\n",
    "print(val_split)\n",
    "print(test_split)\n",
    "val_limit = train_split + val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "train_img_pixel_val_flat = final_inp[0:train_split]\n",
    "val_img_pixel_val_flat = final_inp[train_split:val_limit]\n",
    "test_img_pixel_val_flat = final_inp[val_limit:total_rows]\n",
    "row_len_train=train_img_pixel_val_flat.shape[0]\n",
    "print(row_len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_labels = final_label[0:train_split]\n",
    "val_train_labels = final_label[train_split:val_limit]\n",
    "test_train_labels = final_label[val_limit:total_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_img_pixel_val_flat = final_inp[0:18]\n",
    "print(train_img_pixel_val_flat.shape[0])\n",
    "data = final_inp[36:54]\n",
    "train_img_pixel_val_flat = np.append(train_img_pixel_val_flat, data, axis=0)\n",
    "row_len_train=train_img_pixel_val_flat.shape[0]\n",
    "print(row_len_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_img_pixel_val_flat = final_inp[18:27]\n",
    "print(val_img_pixel_val_flat.shape[0])\n",
    "data = final_inp[54:63]\n",
    "val_img_pixel_val_flat = np.append(val_img_pixel_val_flat, data, axis=0)\n",
    "val_img_pixel_val_flat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_img_pixel_val_flat = final_inp[27:36]\n",
    "print(test_img_pixel_val_flat.shape[0])\n",
    "data = final_inp[63:72]\n",
    "test_img_pixel_val_flat = np.append(test_img_pixel_val_flat, data, axis=0)\n",
    "test_img_pixel_val_flat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_train_labels = final_label[0:18]\n",
    "print((train_train_labels.shape))\n",
    "label = final_label[36:54]\n",
    "train_train_labels = np.append(train_train_labels, label, axis=0)\n",
    "print((train_train_labels.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_train_labels = final_label[18:27]\n",
    "print((val_train_labels.shape))\n",
    "label = final_label[54:63]\n",
    "val_train_labels = np.append(val_train_labels, label, axis=0)\n",
    "print((val_train_labels.shape))\n",
    "#print(val_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_train_labels = final_label[27:36]\n",
    "print((test_train_labels.shape))\n",
    "label = final_label[63:72]\n",
    "test_train_labels = np.append(test_train_labels, label, axis=0)\n",
    "print((test_train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  0.,  0.,  1.,  2.,  1.,  2.,  2.,  1.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  1.,  0.,  2.,  0.,  1.,  1.,  2.,  1.,  2.,\n",
       "        1.,  2.,  0.,  0.,  2.,  0.,  1.,  2.,  0.,  2.,  1.,  1.,  2.,\n",
       "        1.,  0.,  1.,  1.,  2.,  0.,  2.,  1.,  2.,  1.,  2.,  1.,  0.,\n",
       "        0.,  1.,  1.,  0.,  2.,  2.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "        0.,  2.,  2.,  1.,  2.,  1.,  0.,  2.,  1.,  2.,  2.,  1.,  0.,\n",
       "        0.,  2.,  0.,  2.,  2.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values = np.empty((0))\n",
    "for i in range(len(train_train_labels)):\n",
    "     train_values = np.append(train_values, np.argmax(train_train_labels[i]))\n",
    "        \n",
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.]), array([28, 28, 30], dtype=int64))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.,  1.,  0.,  1.,  2.,  1.,  2.,  0.])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_values = np.empty((0))\n",
    "for i in range(len(val_train_labels)):\n",
    "     val_values = np.append(val_values, np.argmax(val_train_labels[i]))\n",
    "        \n",
    "val_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  2.,  2.,  2.,  2.,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values = np.empty((0))\n",
    "for i in range(len(test_train_labels)):\n",
    "     test_values = np.append(test_values, np.argmax(test_train_labels[i]))\n",
    "        \n",
    "test_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_img_pixel_val_flat, train_train_labels =shuffle(train_img_pixel_val_flat, train_train_labels, random_state = 0 )\n",
    "val_img_pixel_val_flat, val_train_labels =shuffle(val_img_pixel_val_flat, val_train_labels, random_state = 0 )\n",
    "test_img_pixel_val_flat, test_train_labels =shuffle(test_img_pixel_val_flat, test_train_labels, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (?, 97200)\n",
      "rows None\n",
      "Saving graph to: C:\\Users\\saish\\AppData\\Local\\Temp\\tmp3_7oz4o6\n",
      "step 0, training accuracy 0.337209\n",
      "step 20, training accuracy 0.988372\n",
      "step 40, training accuracy 1\n",
      "step 60, training accuracy 1\n",
      "step 80, training accuracy 1\n",
      "Validation accuracy 1\n",
      "test accuracy 1\n",
      "arr [1 0 0 0 2 2 2 2 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "def deepnn(x, n_class):\n",
    "    \n",
    "  num_rows, num_cols = x.get_shape().as_list()\n",
    "  print('rows', num_rows)\n",
    "    \n",
    "  #rows, columns = map(lambda i: i.value, x.get_shape())\n",
    "  #print('rows', rows)\n",
    "\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 180, 180, 3])\n",
    "\n",
    "  with tf.name_scope('conv1'):\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  with tf.name_scope('pool1'):\n",
    "     h_pool1 = max_pool_2x2(h_conv1)\n",
    " \n",
    "  with tf.name_scope('conv2'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    " \n",
    "  with tf.name_scope('pool2'):\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  with tf.name_scope('conv3'):\n",
    "    W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "    b_conv3 = bias_variable([128])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    " \n",
    "  with tf.name_scope('pool3'):\n",
    "    h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "  with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([23 * 23 * 128, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 23*23*128])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  \n",
    "  with tf.name_scope('fc2'):\n",
    "    W_fc2 = weight_variable([1024, n_class])\n",
    "    b_fc2 = bias_variable([n_class])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "  return y_conv, keep_prob\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \n",
    "    \n",
    "    x  = tf.placeholder(tf.float32, [None, 97200])\n",
    "    print('x', x.shape)\n",
    "    y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "    y_conv, keep_prob = deepnn(x, 3)\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                            logits=y_conv)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        \n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.argmax(y_conv, 1)\n",
    "        \n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(prediction, tf.argmax(y_, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    graph_location = tempfile.mkdtemp()\n",
    "    print('Saving graph to: %s' % graph_location)\n",
    "    train_writer = tf.summary.FileWriter(graph_location)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(100):\n",
    "            inp_size = np.arange(train_img_pixel_val_flat.shape[0])\n",
    "            np.random.shuffle(inp_size)\n",
    "            #print (inp_size)\n",
    "            #\n",
    "            shuffle_tr_img_pixel_val_flat = train_img_pixel_val_flat[inp_size]\n",
    "            shuffle_tr_test_labels = train_train_labels[inp_size]\n",
    "            #print(shuffle_tr_img_pixel_val_flat.shape)\n",
    "            #print(shuffle_tr_test_labels.shape)\n",
    "            #\n",
    "            if i % 20 == 0:\n",
    "                mode = 'train'\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={x: shuffle_tr_img_pixel_val_flat, y_: shuffle_tr_test_labels, keep_prob: 1.0})\n",
    "                \n",
    "                #arr = prediction.eval(feed_dict={x: img_pixel_val_flat, y_: b, keep_prob: 1.0})\n",
    "                \n",
    "                #print('arr',arr)\n",
    "                print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "            train_step.run(feed_dict={x: shuffle_tr_img_pixel_val_flat, y_: shuffle_tr_test_labels, keep_prob: 0.5})\n",
    "        ##\n",
    "        mode = 'val'\n",
    "        print('Validation accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: val_img_pixel_val_flat, y_: val_train_labels, keep_prob: 1.0}))\n",
    "        \n",
    "        ##\n",
    "        mode = 'test'\n",
    "        arr = prediction.eval(feed_dict={x: test_img_pixel_val_flat, y_: test_train_labels, keep_prob: 1.0})\n",
    "                \n",
    "        ##\n",
    "        mode = 'val'\n",
    "        print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: test_img_pixel_val_flat, y_: test_train_labels, keep_prob: 1.0}))\n",
    "        \n",
    "        print('arr',arr)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
